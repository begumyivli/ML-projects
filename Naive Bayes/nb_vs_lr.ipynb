{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8    \n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  \\\n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29   \n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('wdbc.data', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([0,1], axis=1)\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2      3       4       5        6        7       8        9       10   \n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419  \\\n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        11  ...     22     23      24      25      26      27      28      29   \n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       6.981000\n",
       "3       9.710000\n",
       "4      43.790000\n",
       "5     143.500000\n",
       "6       0.052630\n",
       "7       0.019380\n",
       "8       0.000000\n",
       "9       0.000000\n",
       "10      0.106000\n",
       "11      0.049960\n",
       "12      0.111500\n",
       "13      0.360200\n",
       "14      0.757000\n",
       "15      6.802000\n",
       "16      0.001713\n",
       "17      0.002252\n",
       "18      0.000000\n",
       "19      0.000000\n",
       "20      0.007882\n",
       "21      0.000895\n",
       "22      7.930000\n",
       "23     12.020000\n",
       "24     50.410000\n",
       "25    185.200000\n",
       "26      0.071170\n",
       "27      0.027290\n",
       "28      0.000000\n",
       "29      0.000000\n",
       "30      0.156500\n",
       "31      0.055040\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       28.11000\n",
       "3       39.28000\n",
       "4      188.50000\n",
       "5     2501.00000\n",
       "6        0.16340\n",
       "7        0.34540\n",
       "8        0.42680\n",
       "9        0.20120\n",
       "10       0.30400\n",
       "11       0.09744\n",
       "12       2.87300\n",
       "13       4.88500\n",
       "14      21.98000\n",
       "15     542.20000\n",
       "16       0.03113\n",
       "17       0.13540\n",
       "18       0.39600\n",
       "19       0.05279\n",
       "20       0.07895\n",
       "21       0.02984\n",
       "22      36.04000\n",
       "23      49.54000\n",
       "24     251.20000\n",
       "25    4254.00000\n",
       "26       0.22260\n",
       "27       1.05800\n",
       "28       1.25200\n",
       "29       0.29100\n",
       "30       0.66380\n",
       "31       0.20750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "5     0.000000\n",
      "6     0.052630\n",
      "7     0.019380\n",
      "8     0.000000\n",
      "9     0.000000\n",
      "10    0.106000\n",
      "11    0.049960\n",
      "12    0.000000\n",
      "13    0.000000\n",
      "14    0.000000\n",
      "15    0.000000\n",
      "16    0.001713\n",
      "17    0.002252\n",
      "18    0.000000\n",
      "19    0.000000\n",
      "20    0.007882\n",
      "21    0.000895\n",
      "22    0.000000\n",
      "23    0.000000\n",
      "24    0.000000\n",
      "25    0.000000\n",
      "26    0.071170\n",
      "27    0.000000\n",
      "28    0.000000\n",
      "29    0.000000\n",
      "30    0.156500\n",
      "31    0.055040\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_chosen_data(df, target_column=None, exclude_columns=[]):\n",
    "    normalized_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column != target_column and column not in exclude_columns:\n",
    "            max_value = df[column].max()\n",
    "            min_value = df[column].min()\n",
    "            if min_value < 0 or max_value > 1:  # Normalize only if out of the [0,1] range\n",
    "                normalized_df[column] = (df[column] - min_value) / (max_value - min_value)\n",
    "    return normalized_df\n",
    "\n",
    "# columns that do not need normalization (already in the range 0-1)\n",
    "exclude_columns = [col for col in X.columns if X[col].min() >= 0 and X[col].max() <= 1]\n",
    "\n",
    "X = normalize_chosen_data(X, exclude_columns=exclude_columns)\n",
    "\n",
    "print(X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     1.00000\n",
      "3     1.00000\n",
      "4     1.00000\n",
      "5     1.00000\n",
      "6     0.16340\n",
      "7     0.34540\n",
      "8     0.42680\n",
      "9     0.20120\n",
      "10    0.30400\n",
      "11    0.09744\n",
      "12    1.00000\n",
      "13    1.00000\n",
      "14    1.00000\n",
      "15    1.00000\n",
      "16    0.03113\n",
      "17    0.13540\n",
      "18    0.39600\n",
      "19    0.05279\n",
      "20    0.07895\n",
      "21    0.02984\n",
      "22    1.00000\n",
      "23    1.00000\n",
      "24    1.00000\n",
      "25    1.00000\n",
      "26    0.22260\n",
      "27    1.00000\n",
      "28    1.00000\n",
      "29    0.29100\n",
      "30    0.66380\n",
      "31    0.20750\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.apply(lambda x: 1 if x == 'M' else 0)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - Features: (399, 30) Labels: (399,)\n",
      "Test set - Features: (170, 30) Labels: (170,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    indices = np.arange(m)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_samples = int(test_size * m)\n",
    "    \n",
    "    test_indices = indices[:test_samples]\n",
    "    train_indices = indices[test_samples:]\n",
    "    \n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape, \"Labels:\", y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, \"Labels:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.01874354 -0.84188583  0.18327536  0.8560901  -0.85884797 -0.08323775\n",
      "  0.87491207  0.47728596 -1.58931903 -0.68423421  0.69916078 -1.49359956\n",
      "  0.59937705  0.74628303 -0.07737002 -0.10842442 -0.11281367 -0.04506341\n",
      " -0.19816877 -0.03600239  0.94700587 -0.53829666  0.99763818  1.30749655\n",
      " -1.06051679  0.68956216  1.34216572  0.52126522 -2.02645327 -0.71014384]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def computeGradient(X, y, y_pred):\n",
    "    return np.dot(X.T, (y_pred - y)) / y.shape[0]\n",
    "\n",
    "def logistic_regression_GD(X, y, lr=0.1, iterations=1000):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_pred = sigmoid(np.dot(X, w))  \n",
    "        gradient = computeGradient(X, y, y_pred)  \n",
    "        w -= lr * gradient\n",
    "        \n",
    "        # calculate loss\n",
    "        epsilon = 1e-5  # adding a small constant to prevent log0\n",
    "        loss = -np.mean(y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "        losses.append(loss)\n",
    "\n",
    "    return w, losses\n",
    "\n",
    "weights, losses = logistic_regression_GD(X_train, y_train, lr=0.1, iterations=1000)\n",
    "\n",
    "print(\"Weights:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ -5.62575886  -1.99418032  -4.2429034    3.20268663  -6.43762668\n",
      "  -1.23515008   6.576742     5.68160497 -11.34904651  -6.34489376\n",
      "   7.04350353  -6.42146788   3.67992699   5.98119655  -0.51740229\n",
      "  -2.63304048  -4.25857001  -0.55992309  -0.80110278  -0.52978591\n",
      "   4.82114107   6.92189026   3.61081288   8.47446463  -7.08678238\n",
      "   2.99410714   4.77115423   5.83727661  -6.86573496  -6.58769215]\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_SGD(X, y, lr=0.01, iterations=1000):\n",
    "    m = X.shape[0]\n",
    "    w = np.zeros(X.shape[1])\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        permutation = np.random.permutation(m)\n",
    "        X_shuffled = X.values[permutation]\n",
    "        y_shuffled = y.values[permutation]\n",
    "        \n",
    "        for j in range(m):\n",
    "            # pick a random sample\n",
    "            X_sample = X_shuffled[j]\n",
    "            y_sample = y_shuffled[j]\n",
    "            \n",
    "            y_pred = sigmoid(np.dot(X_sample, w))\n",
    "            gradient = np.dot(X_sample.T, (y_pred - y_sample))\n",
    "            \n",
    "            # calculate loss\n",
    "            epsilon = 1e-15\n",
    "            loss = - (y_sample * np.log(y_pred + epsilon) + (1 - y_sample) * np.log(1 - y_pred + epsilon))\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            # update weights\n",
    "            w -= lr * gradient\n",
    "            \n",
    "        losses.append(epoch_loss / m)\n",
    "    \n",
    "    return w, losses\n",
    "\n",
    "weights, losses = logistic_regression_SGD(X_train, y_train, iterations=1000)\n",
    "print(\"Weights:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.01972524 -0.83375671  0.18231773  0.84713367 -0.84895531 -0.08224685\n",
      "  0.86490412  0.47182643 -1.57102819 -0.67633558  0.69116812 -1.47753922\n",
      "  0.59256595  0.73778909 -0.07649023 -0.10715468 -0.11143101 -0.04453416\n",
      " -0.19591975 -0.03558458  0.93703105 -0.53421763  0.98704589  1.29309318\n",
      " -1.04837378  0.6814196   1.32681445  0.51530475 -2.00340117 -0.70197637]\n"
     ]
    }
   ],
   "source": [
    "def computeRegularizingTerm(lambda_val, w, y):\n",
    "    return lambda_val * w / y.shape[0]\n",
    "\n",
    "def logistic_regression_L2_GD(X, y, lr=0.1, lambda_val=0.1, iterations=1000):\n",
    "    w = np.zeros(X.shape[1])  \n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_pred = sigmoid(np.dot(X, w))  \n",
    "        gradient_w = computeGradient(X, y, y_pred) + computeRegularizingTerm(lambda_val, w, y)\n",
    "        w -= lr * gradient_w  \n",
    "        \n",
    "        # calculate loss\n",
    "        epsilon = 1e-5  # adding a small constant to prevent log0\n",
    "        loss = -np.mean(y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "        losses.append(loss)\n",
    "\n",
    "    return w, losses\n",
    "\n",
    "weights, losses = logistic_regression_L2_GD(X_train, y_train, iterations=1000)\n",
    "print(\"Weights:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.06189548 -0.14406591  0.08107376  0.15797161 -0.10463449 -0.00565317\n",
      "  0.11840965  0.06472871 -0.19502932 -0.08355995  0.1053756  -0.21980307\n",
      "  0.09262707  0.1131838  -0.00984932 -0.01227857 -0.01041895 -0.00491613\n",
      " -0.02537115 -0.00430546  0.16934229 -0.12309746  0.17340539  0.20463293\n",
      " -0.13126932  0.08545478  0.17894328  0.07180613 -0.25619876 -0.08736372]\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_L2_SGD(X, y, lr=0.01, lambda_val=0.1, iterations=1000):\n",
    "    m = X.shape[0]\n",
    "    w = np.zeros(X.shape[1])\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        permutation = np.random.permutation(m)\n",
    "        X_shuffled = X.values[permutation]\n",
    "        y_shuffled = y.values[permutation]\n",
    "        \n",
    "        for j in range(m):\n",
    "            # pick a random sample\n",
    "            X_sample = X_shuffled[j]\n",
    "            y_sample = y_shuffled[j]\n",
    "            \n",
    "            y_pred = sigmoid(np.dot(X_sample, w))\n",
    "            gradient = (np.dot(X_sample.T, (y_pred - y_sample)) + lambda_val * w)\n",
    "            \n",
    "            # calculate loss\n",
    "            epsilon = 1e-15\n",
    "            loss = - (y_sample * np.log(y_pred + epsilon) + (1 - y_sample) * np.log(1 - y_pred + epsilon))\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            # update weights\n",
    "            w -= lr * gradient\n",
    "        losses.append(epoch_loss / m)\n",
    "    \n",
    "    return w, losses\n",
    "\n",
    "weights, losses = logistic_regression_L2_SGD(X_train, y_train, iterations=1000)\n",
    "print(\"Weights:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9176470588235294\n",
      "Train Accuracy: 0.849624060150376\n"
     ]
    }
   ],
   "source": [
    "def predict(X, w):\n",
    "    y_pred_proba = sigmoid(np.dot(X, w))\n",
    "    y_pred = []\n",
    "    for prob in y_pred_proba:\n",
    "        if prob >= 0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_pred = predict(X_test, weights)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "y_pred_train = predict(X_train, weights)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_test = np.mean(y_pred == y_test)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "accuracy_train = np.mean(y_pred_train == y_train)\n",
    "print(\"Train Accuracy:\", accuracy_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
